---
title: Polygenic Risk Score (PRS) Introduction 401 
subtitle: heterogeneity and PRS transportabiliy  
author: Drs. Lei Sun, Wei Deng, Yanyan Zhao
institute:
  - Department of Statistical Sciences, FAS  
  - Division of Biostatistics, DLSPH  
  - University of Toronto    
date: "`r format(Sys.time(), '%d %B, %Y')`"

output: 
  beamer_presentation: 
    pandoc_args: ["--extract-media", "./extracted-image"]
# output: word_document
# output: html_document
# output: pdf_document

header-includes:
 - \usepackage{fancyhdr}
 - \usepackage{amsmath,latexsym}
 - \hypersetup{colorlinks=true, linkcolor=blue}
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_chunk$set(out.width = '70%') 
set.seed(1234) 
library(knitr)
library(kableExtra)
library(plotly)
library(fields) 
```

## At the end of this lecture, a **deeper** understanding of  

Effects of various (population and locus) **heterogeneities**, and the importance of reference allele (and genome build) matching.
\begin{itemize}
\item my.reference.allele $\neq$ reference.allele
\item my.maf $\neq$ ex.maf
\item my.beta.true $\neq$ ex.beta.true
\item my.nsnp.true $\neq$ ex.nsnp.true
\end{itemize}


```{r,echo=FALSE,out.width = '50%',fig.align = "center"}
generate.ex.sumstat=function(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma) #the function assumes first ex.nsnp.true are causal and effect size all equal to ex.beta.true
{
  set.seed(ex.seed) 
  ex.G=matrix(-9,nrow = ex.nsample,ncol = ex.nsnp)
  ex.maf=runif(ex.nsnp,min=0.05,max=0.5)
  ex.maf.hat=rep(-9,ex.nsnp)
  ex.beta=c(rep(ex.beta.true,ex.nsnp.true),rep(0,(ex.nsnp-ex.nsnp.true)))
  ex.betaG=rep(0,ex.nsample)
  for(j in 1:ex.nsnp){
    ex.nG=rmultinom(1,size=ex.nsample,prob=c((1-ex.maf[j])^2,2*ex.maf[j]*(1-ex.maf[j]), ex.maf[j]^2))
    ex.maf.hat[j]=(2*ex.nG[3]+ex.nG[2])/(2*ex.nsample)
    ex.G[,j]=sample(c(rep(0,ex.nG[1]),rep(1,ex.nG[2]),rep(2,ex.nG[3]))) # shuffle the G; no LD
    ex.betaG=ex.betaG+ex.beta[j]*ex.G[,j]
    }
  ex.beta.0=0;ex.e=rnorm(ex.nsample,mean=0,sd=ex.sigma) 
  ex.Y=ex.beta.0+ex.betaG+ex.e
  
  ex.sumstat=matrix(-9,nrow=ex.nsnp,ncol=7)
  colnames(ex.sumstat)=c("MAF", "MAF.hat", "beta", "beta.hat", "se", "Z.value", "p.value")
  for(j in 1:ex.nsnp){
    ex.fit=lm(ex.Y~ex.G[,j])
    ex.sumstat[j,]=c(ex.maf[j],ex.maf.hat[j],ex.beta[j],summary(ex.fit)$coefficients[2,])
  }
  
  return(ex.sumstat)
}
```

\tiny
```{r,echo=FALSE,out.width = '70%',fig.align = "center"}
generate.my.data=function(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf) # the function assumes my.nsnp=ex.nsp & the first my.nsnp.true are causal and with the same effect size of my.beta.true
{
  set.seed(my.seed) 
  my.data=list()
  
  my.beta=c(rep(my.beta.true,my.nsnp.true),rep(0,(my.nsnp-my.nsnp.true))) 
  my.maf.hat=rep(-9,my.nsnp) 
  my.G=matrix(-9,nrow = my.nsample,ncol = my.nsnp)
  my.betaG=rep(0,my.nsample)
  
  for(j in 1:my.nsnp){
    my.nG=rmultinom(1,size=my.nsample,prob=c((1-my.maf[j])^2,2*my.maf[j]*(1-my.maf[j]), my.maf[j]^2))
    my.maf.hat[j]=(2*my.nG[3]+my.nG[2])/(2*my.nsample) 
    my.G[,j]=sample(c(rep(0,my.nG[1]),rep(1,my.nG[2]),rep(2,my.nG[3]))) 
    my.betaG=my.betaG+my.beta[j]*my.G[,j]
    }
  my.beta.0=0;my.e=rnorm(my.nsample,mean=0,sd=my.sigma)
  my.Y=my.beta.0+my.betaG+my.e # the phenotype vector

  my.sumstat=matrix(-9,nrow=my.nsnp,ncol=7)
  colnames(my.sumstat)=c("MAF", "MAF.hat", "beta", "beta.hat", "se", "Z.value", "p.value")
  for(j in 1:my.nsnp){
    my.fit=lm(my.Y~my.G[,j])
    my.sumstat[j,]=c(my.maf[j],my.maf.hat[j],my.beta[j],summary(my.fit)$coefficients[2,])
  }
  
  my.data$my.G=my.G
  my.data$my.Y=my.Y
  my.data$my.Y.STD=(my.Y-mean(my.Y))/sqrt(var(my.Y))
  my.data$my.sumstat=my.sumstat
  return(my.data)
}
```

\tiny
```{r,echo=FALSE,out.width = '50%',fig.align = "center"}
generate.my.PRS.output=function(ex.sumstat,my.data,alpha.level,l.threshold)
{
  my.PRS.output=list()
  
  my.G=my.data$my.G
  my.Y.STD=my.data$my.Y.STD
  my.sumstat=my.data$my.sumstat

  # add  the oracle one as well
  my.PRS.oracle=rep(0,my.nsample)
  my.PRS.oracle.STD=rep(0,my.nsample)
  if(my.nsnp.true>0) { # in case no true causal SNPs
    for (i in 1:my.nsample) 
      for (j in 1:my.nsnp.true) # using all the causal SNPs and using the true effect size from my data
        my.PRS.oracle[i]=my.PRS.oracle[i]+my.sumstat[j,"beta"]*my.G[i,j]
    my.PRS.oracle.STD=(my.PRS.oracle-mean(my.PRS.oracle))/sqrt(var(my.PRS.oracle))
  }
  
  # PRS for the different alpha levels
  my.PRS.alpha=matrix(0,nrow=my.nsample,ncol=length(alpha.level))
  my.PRS.alpha.STD=matrix(0,nrow=my.nsample,ncol=length(alpha.level))
  my.PRS.J.info=matrix(0,nrow=length(alpha.level),ncol=4) 
  colnames(my.PRS.J.info)=c("alpha","J","TP","FP")
  my.PRS.J.info[,1]=alpha.level
  
  for(k in 1:length(alpha.level)) {
    # J index & beta.hat from the external data
    ex.J.index=which(ex.sumstat[,"p.value"]<=alpha.level[k])
    # in case there are no significant SNPs in the external data
    if (length(ex.J.index)>1) {
      my.PRS.J.info[k,2]=length(ex.J.index) 
      my.PRS.J.info[k,3]=length(which(ex.J.index<=my.nsnp.true)) # codes not adaptive as it assumes that ex and my SNPs are matched and the first my.nsnp.true SNPs are the true SNPs
      my.PRS.J.info[k,4]=length(which(ex.J.index>my.nsnp.true))
      
      for (i in 1:my.nsample) 
        for (j in 1:length(ex.J.index)) 
          my.PRS.alpha[i,k]=my.PRS.alpha[i,k]+ex.sumstat[ex.J.index[j],"beta.hat"]*my.G[i,ex.J.index[j]]  # pay attention to the use of ex. and my.

      my.PRS.alpha.STD[,k]=(my.PRS.alpha[,k]-mean(my.PRS.alpha[,k]))/sqrt(var(my.PRS.alpha[,k]))
    }
  }

  # the liability threshold applied to the standardized my.Y
  my.case.index=which(my.Y.STD>l.threshold)
  my.control.index=which(my.Y.STD<=l.threshold)
  my.color.index=rep("black",my.nsample); my.color.index[my.case.index]="red"
  # for ROC and AUC later
  my.Y.cc=rep("0-Control",my.nsample); my.Y.cc[my.case.index]="1-Case"
  my.ncase=sum(my.Y.cc=="1-Case") # total number of cases
  my.ncontrol=sum(my.Y.cc=="0-Control") # total number of controls

  my.PRS.output$my.PRS.oracle=my.PRS.oracle
  my.PRS.output$my.PRS.oracle.STD=my.PRS.oracle.STD
  my.PRS.output$my.PRS.alpha=my.PRS.alpha
  my.PRS.output$my.PRS.alpha.STD=my.PRS.alpha.STD
  my.PRS.output$my.PRS.J.info=my.PRS.J.info
  
  my.PRS.output$my.Y.cc=my.Y.cc 
  my.PRS.output$my.ncase=my.ncase
  my.PRS.output$my.ncontrol=my.ncontrol
  my.PRS.output$my.color.index=my.color.index
  my.PRS.output$my.case.index=my.case.index
  
  return(my.PRS.output)
}
```

\tiny
```{r,echo=FALSE,out.width = '90%',fig.align = "center"}
generate.ss.ROC.AUC=function(my.PRS.output,PRS.STD.input) {

  ss.ROC.AUC=list()
  
  my.Y.cc=my.PRS.output$my.Y.cc
  my.ncase=my.PRS.output$my.ncase
  my.ncontrol=my.PRS.output$my.ncontrol
  
  PRS=PRS.STD.input
  
  a=seq(4,-2.5,by=-0.5) # the range for calling Positives 
  P=rep(-9,length(a));TP=rep(-9,length(a));FP=rep(-9,length(a))
  sensitivity=rep(-9,length(a)); specificity.1=rep(-9,length(a))

  for (k in 1:length(a)) {
    PRS.threshold=a[k]
    P[k]=sum(PRS>PRS.threshold)
    TP[k]=sum(my.Y.cc[PRS>PRS.threshold]=="1-Case")
    FP[k]=sum(my.Y.cc[PRS>PRS.threshold]=="0-Control")
    sensitivity[k]=TP[k]/my.ncase
    specificity.1[k]=FP[k]/my.ncontrol
  }

  auc=0
  for (k in 2:length(a)) # Trapezoid's method height*(base1+base2)/2
    auc = auc + (specificity.1[k]-specificity.1[k-1])*(sensitivity[k]+sensitivity[k-1])/2

  ss.ROC.AUC$sensitivity=sensitivity
  ss.ROC.AUC$specificity.1=specificity.1
  ss.ROC.AUC$auc=auc

  return(ss.ROC.AUC)
}
```

```{r,echo=FALSE,out.width = '90%',fig.align = "center"}
generate.ROC.plot=function(my.PRS.output) {

  my.PRS.output=my.PRS.output
  
  my.PRS.oracle.STD=my.PRS.output$my.PRS.oracle.STD
  my.PRS.alpha.STD=my.PRS.output$my.PRS.alpha.STD
  my.PRS.J.info=my.PRS.output$my.PRS.J.info
  
  method=c("PRS.oracle (0.769)","PRS.gw (0.713)","PRS.01 (0.653)","PRS.1 (0.604)") # This is not adaptive
  auc.method=rep(0,(length(alpha.level)+1)) # the first one is for oracle
  
  if(my.nsnp.true>0) {
    ss.ROC.AUC=generate.ss.ROC.AUC(my.PRS.output,my.PRS.oracle.STD)
    plot(ss.ROC.AUC$specificity.1,ss.ROC.AUC$sensitivity,type="b",pch=20,col="grey",xlab="1 - Specificity = False Positives/ncontrols",ylab="Sensitivity = True Positives/ncases")
    abline(0,1)
    auc.method[1]=ss.ROC.AUC$auc
  } else {
    plot(seq(0,1,0.1),seq(0,1,0.1),type="n",xlab="1 - Specificity = False Positives/ncontrols",ylab="Sensitivity = True Positives/ncases")   
    abline(0,1,col="grey")
    auc.method[1]=0.5
  }
  alpha.level.k=1
  if (my.PRS.J.info[alpha.level.k,2]>0) {
    ss.ROC.AUC=generate.ss.ROC.AUC(my.PRS.output,my.PRS.alpha.STD[,alpha.level.k])
    lines(ss.ROC.AUC$specificity.1,ss.ROC.AUC$sensitivity,type="b",pch=20,col="red")
    auc.method[alpha.level.k+1]=ss.ROC.AUC$auc
  } else {
    abline(0,1,col="red")
    auc.method[alpha.level.k+1]=0.5
  }

  alpha.level.k=2
  if (my.PRS.J.info[alpha.level.k,2]>0) {
    ss.ROC.AUC=generate.ss.ROC.AUC(my.PRS.output,my.PRS.alpha.STD[,alpha.level.k])
    lines(ss.ROC.AUC$specificity.1,ss.ROC.AUC$sensitivity,type="b",pch=20,col="blue")
    auc.method[alpha.level.k+1]=ss.ROC.AUC$auc
  } else {
    abline(0,1,col="blue")
    auc.method[alpha.level.k+1]=0.5
  }

  alpha.level.k=3
  if (my.PRS.J.info[alpha.level.k,2]>0) {
    ss.ROC.AUC=generate.ss.ROC.AUC(my.PRS.output,my.PRS.alpha.STD[,alpha.level.k])
    lines(ss.ROC.AUC$specificity.1,ss.ROC.AUC$sensitivity,type="b",pch=20,col="green")
    auc.method[alpha.level.k+1]=ss.ROC.AUC$auc
  } else {
    abline(0,1,col="green")
    auc.method[alpha.level.k+1]=0.5
  }

  legend(0.6, 0.37, paste(round(auc.method,3),method), lty=1, lwd=2, col=c("grey","red","blue","green"),cex=1.3)

  print(my.PRS.J.info)
}
```

\tiny  
```{r,echo=FALSE,out.width = '90%',fig.align = "center"}
generate.association.plot=function(my.PRS.output){
  
  my.PRS.oracle.STD=my.PRS.output$my.PRS.oracle.STD
  my.PRS.alpha.STD=my.PRS.output$my.PRS.alpha.STD
  my.color.index=my.PRS.output$my.color.index
  my.Y.STD=my.data$my.Y.STD
  my.PRS.J.info=my.PRS.output$my.PRS.J.info
  my.ncase=my.PRS.output$my.ncase
  my.ncontrol=my.PRS.output$my.ncontrol
  
  par(mfrow=c(1,4))
  temp=matrix(0, nrow=(length(alpha.level)+1),ncol=4)
  
  # the orcale one
  if (my.nsnp.true>0) {
    plot(my.PRS.oracle.STD,my.Y.STD,col=my.color.index,xlab="Oracle")
    fit=lm(my.Y.STD~my.PRS.oracle.STD);abline(a=fit$coef[1],b=fit$coef[2],lty=2)
    temp[1,]=summary(fit)$coefficients[2,]
  } else {
    plot(my.PRS.oracle.STD,my.Y.STD,col=my.color.index,xlab="Oracle")
    temp[1,]=c(-9,-9,-9,-9)
  }
  
  # the alpha ones
  for(k in 1:length(alpha.level)){
    if (my.PRS.J.info[k,2]>0) {
      plot(my.PRS.alpha.STD[,k],my.Y.STD,col=my.color.index,xlab=paste("alpha=",alpha.level[k]))
      fit=lm(my.Y.STD~my.PRS.alpha.STD[,k]);abline(a=fit$coef[1],b=fit$coef[2],lty=2)
      temp[k+1,]=summary(fit)$coefficients[2,] # the first one for oracle
    }
    else {
      plot(my.PRS.alpha.STD[,k],my.Y.STD,col=my.color.index,xlab=paste("alpha=",alpha.level[k]))
      temp[k+1,]=c(-9,-9,-9,-9)
    }
  }

  temp=rbind(c("slope.hat", round(temp[,1],3)), c("Z.value", round(temp[,3],3)), c("p.value", signif(temp[,4],digits=4)),c("n, case, control", (my.ncase+my.ncontrol), my.ncase, my.ncontrol, " "))
  print(temp)
}
```

\tiny
```{r,echo=FALSE,out.width = '95%',fig.align = "center"}
generate.sumstat.plot=function(sumstat){
  par(mfrow=c(2,2))
  hist(sumstat[,"beta.hat"],freq=F)
  curve(dnorm(x,mean=0, sd=(sqrt(var(sumstat[,"beta.hat"])))), add=T,lwd=2,col="blue")
  hist(sumstat[,"Z.value"],freq=F)
  curve(dnorm(x,mean=0, sd=1), add=T,lwd=2,col="blue")
  hist(sumstat[,"p.value"],freq=F)
  abline(h=1,col="blue")
  plot(-log10((seq(1,ex.nsnp,1)-0.5)/ex.nsnp), -log10(sort(sumstat[,"p.value"])),ylab="-log(p-value) Obs", xlab="-log(p-value) Exp",main="QQ-plot of p-value")
  abline(0,1,lwd=2,col="blue")
}
```


## Recall the baseline model without any heterogeneity  

\footnotesize
10 out 5000 indep.\ SNPs with **varying `moderate-large' effects** are truly associated with $Y$ (**all $\beta=0.3$ but MAF vary**).  
$$Y_i=\sum_{j=1}^{10} \beta_jG_{ij} + e, \text{ where } \beta_j=0.3$$   
$$\text{ MAF} \sim \text{  Unif(0.05,0.5)}, \: e\sim N(0,1).$$  

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
# external data
ex.nsnp.true=10; ex.beta.true=0.3
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{3pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \footnotesize Recall the different \color{red}$PRS_i=\sum_{j=1}^{J} \hat \beta_j G_{ij}$  
\small
**Using the GW threshold on the external data**  
$$my.PRS_{GW}=\sum_{j=1}^{6} \hat \beta_j^{external}\times G_{ij}^{my.data}$$ 
\vspace{6pt}

**Using $\alpha=0.01$ (and also add $\alpha=0.1$) on the external data**  
$$my.PRS_{.01} \text{ (or } my.PRS_{.1} \text{) }=\sum_{j=1}^{66 \text{ (or } 492 \text{) }} \hat \beta_j^{external}\times G_{ij}^{my.data}$$
  
\vspace{6pt}

**The oracle one** (benchmarking the upper bound)
$$my.PRS_{oracle}=\sum_{j=1}^{10} 0.3 \times G_{ij}^{my.data}$$
  
## The baseline model ROC and AUC   

\tiny
```{r,echo=FALSE,out.width = '70%',fig.align = "center"}
alpha.level=c((0.05/ex.nsnp),0.01,0.1)
l.threshold=1
```

```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)  
```
  
## \tiny the baseline model
\tiny  
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
generate.association.plot(my.PRS.output)
```

## \tiny the baseline model
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## Getting to heterogeneity \& transportability; first

\color{red} Live Quiz 5: If my.MAF = 1 - ex.MAF but everything else stay the same, the AUC of the PRS’s will 

A: drop a bit  
B: drop a lot  
C: stay ~ the same  
D: stay exactly the same  

## my.MAF = 1-ex.MAF
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=10; ex.beta.true=0.3
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf= 1-ex.sumstat[,"MAF"] # HERE is the change
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model (Quiz: Why the same?)**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny my.MAF = 1-ex.MAF
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny my.MAF = 1-ex.MAF
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## my.MAF = 1 - ex.MAF means MAF heterogeneity, BUT  

\small
$p_j(1-p_j)=(1-p_j)p_j$, and in general MAF heterogeneity alone does not have a huge impact on AUC, even if my.MAF independent of ex.MAF:  
\vspace{12pt} 

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=10; ex.beta.true=0.3
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3
my.seed=105;set.seed(my.seed) # try other seeds and results in general stable.
my.maf= runif(my.nsnp,min=0.05,max=0.5) # HERE is the change
my.nsnp=5000; my.nsample=1000; my.sigma=1
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny my.MAF independent of ex.MAF
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny my.MAF independent of ex.MAF
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## Make my.reference.allele $\neq$ ex.reference.allele  

Assume all reference alleles have been switched.   
An easy way to achieve this is   
**changing the sign of the beta of ex.sumstat.**
\vspace{12pt}

\color{red} Live Quiz 6: Switch the reference allele between my.data and
ex.data, the AUC of the PRS’s will drop to  
  
A: still >50%  
B: ~50%  
C: < 50%  

## Switch the reference allele
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=10; ex.beta.true=0.3
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)
ex.sumstat[,"beta"]=(-ex.sumstat[,"beta"]) # HERE is the change
ex.sumstat[,"beta.hat"]=(-ex.sumstat[,"beta.hat"]) # HERE is the change

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model (recall: $\beta_j^2p_j(1-p_j)$)**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny Switch the reference allele
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## \tiny Switch the reference allele
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny Switch the reference allele
\tiny  
```{r,echo=TRUE,out.width = '90%',fig.align = "center"}
generate.association.plot(my.PRS.output)
```

## Lessons learned so far and more questions

**Reference allele (and genome build) matching is really important!**  
\vspace{12pt}

(Population) heterogeneity can lead to MAF heterogeneity, which on its own does not have a big impact on PRS performance.  
\vspace{12pt}

(Population) heterogeneity can also lead to **my.beta.true $\neq$ ex.beta.true**.  
\small

- As ex.beta.true decreases, PRS performance decreases: obvious  
- **As ex.beta.true increases, PRS performance increases?**     
- Quiz: **as ex.beta.true increases, can AUC increases to ~100\%?**   

## (Population) heterogeneity: decrease ex.beta.true to 0.3/2

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=10; ex.beta.true=0.3/2 # HERE is the only change
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model** ($\frac14 V_G/(\frac14 V_G+ \sigma^2)=\frac14 0.321/(\frac14 0.321+ 1)=0.074$)
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny (Population) heterogeneity: decrease ex.beta.true to 0.3/2 
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny (Population) heterogeneity: decrease ex.beta.true to 0.3/2  
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```


## (Population) heterogeneity: increase ex.beta.true to 0.3*2

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=10; ex.beta.true=0.3*2 # HERE is the only change
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model** ($\frac41 V_G/(\frac41 V_G+ \sigma^2)=\frac41 0.321/(\frac41 0.321+ 1)=0.562$)
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny (Population) heterogeneity: increase ex.beta.true to 0.3*2 
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny (Population) heterogeneity: increase ex.beta.true to 0.3*2  
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## (Locus) heterogeneity: my.nsnp.true$\neq$ex.nsnp.true; ex.nsnp.true reduced to 5  

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=5 # HERE is the only change 
ex.beta.true=0.3 
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny (Locus) heterogeneity: ex.nsnp.true reduced to 5  
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny (Locus) heterogeneity: ex.nsnp.true reduced to 5   
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[1:13,]
```
\vspace{6pt}  
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:13,]
```

## A milestone Quiz

\color{red} Live Quiz 7: compared with the baseline model, if ex.snp.true=50 the AUC of say PRS.gw will 
  
A: increase  
B: decrease  
C: ~same  

## (Locus) heterogeneity: my.nsnp.true$\neq$ex.nsnp.true, ex.nsnp.true increased to 50

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=50 # HERE is the only change 
ex.beta.true=0.3 
ex.nsnp=5000; ex.nsample=1000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny (Locus) heterogeneity: ex.nsnp.true increased to 50  
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny (Locus) heterogeneity: ex.nsnp.true increased to 50
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[c(1:10,49,50,51,52),] # the actual 1:14 rows
```
\vspace{6pt}
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:12,]
```

## Understanding the `disturbing' results, e.g. at $10^{-5}$ 
  
\footnotesize
10 ex.data \& 10 my.data: 6 Ps in ex.data, all 6 are TPs in my.data  
  
50 ex.data \& 10 my.data: only 13 Ps in ex.data, and only 3 are TPs in my.data
     
**50 causal SNPs leads to higher total heritability**

\tiny
$$\text{(narrow) } h^2=\frac{V_G}{V_G+V_e}=\frac{\sum_j^{50} \beta_j^2 Var(G_j)}{Var(Y)}=\frac{{\sum_j^{50} \beta_j^2 2p_j(1-p_j)}}{\sum_j^{50}  \beta_j^2 2p_j(1-p_j)+\sigma^2}.$$  
\footnotesize    
BUT, **smaller SNP heritability**:  
\tiny
$$\text{(narrow) } h_{j}^2=\frac{{\beta_j^2 2p_j(1-p_j)}}{\sum_j^{50}  \beta_j^2 2p_j(1-p_j)+\sigma^2}.$$

\tiny
**Total and SNP $h^2$ of ex.model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(c(V.G, V.e, V.G/(V.G+V.e)),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci[1:20]/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my.model (the same as the baseline ex.model)**
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(c(V.G, V.e, V.G/(V.G+V.e)),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## Will a larger $n$ help?   
\footnotesize
(Not dramatically, as although it helps identify more ex.nsnp.true, many of the ex.nsnp.true are NOT my.nsnp.true)  
\vspace{6pt}

\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}

# external data
ex.nsnp.true=50 # HERE is the change & ex.nsample also increased
ex.beta.true=0.3 
ex.nsnp=5000; ex.nsample=2000; ex.sigma=1; ex.seed=101
ex.sumstat=generate.ex.sumstat(ex.seed,ex.nsample,ex.nsnp,ex.nsnp.true,ex.beta.true,ex.sigma)

# my data
my.nsnp.true=10; my.beta.true=0.3; my.maf=ex.sumstat[,"MAF"] 
my.nsnp=5000; my.nsample=1000; my.sigma=1; my.seed=102
my.data=generate.my.data(my.seed,my.nsample,my.nsnp,my.nsnp.true,my.beta.true,my.sigma,my.maf)
```

**Total and SNP $h^2$ of the external model**
```{r,echo=FALSE}
V.G=sum(ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"])))
V.e=ex.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=ex.sumstat[1:ex.nsnp.true,"beta"]^2*(2*ex.sumstat[1:ex.nsnp.true,"MAF"]*(1-ex.sumstat[1:ex.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```
\vspace{6pt}

**Total and SNP $h^2$ of my model** (the true $h^2$ does not depend on $n$)
```{r,echo=FALSE}
my.sumstat=my.data$my.sumstat
V.G=sum(my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"])))
V.e=my.sigma^2
round(V.G/(V.G+V.e),3)
V.G.loci=my.sumstat[1:my.nsnp.true,"beta"]^2*(2*my.sumstat[1:my.nsnp.true,"MAF"]*(1-my.sumstat[1:my.nsnp.true,"MAF"]))
round(V.G.loci/(V.G+V.e),3)
```

## \tiny ex.nsnp.true increased to 50 and ex.nsample to 2000
\tiny
```{r,echo=TRUE,out.width = '85%',fig.align = "center"}
# generate the ROC plots
my.PRS.output=generate.my.PRS.output(ex.sumstat,my.data,alpha.level,l.threshold)
generate.ROC.plot(my.PRS.output)
```

## \tiny ex.nsnp.true increased to 50 and ex.nsample to 2000  
\tiny
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
ex.sumstat[c(1:10,49,50,51,52),] # the actual 1:14 rows
```
\vspace{6pt}
```{r,echo=TRUE,out.width = '70%',fig.align = "center"}
my.data$my.sumstat[1:12,]
```

## What does this tell us?   
\small  
- More truly associated SNPs lead to high trait heritability, but it does not translate to improved power of (standard) GWAS or PRS performance.  
\vspace{3pt}  

- Power of standard GWAS depends on the SNP heritability.  
\vspace{12pt}   

- Thus, using ex.data for a trait with high trait heritability does necessarily lead to better PRs performance in my.data.  
\vspace{12pt}  

- Heterogeneity (ex.data and my.data not matching) is damaging and can lead to counter-intuitive results.  
\vspace{3pt}  

- e.g. Larger $n$ may not be better if heterogeneity is not properly addressed.  

## Should study more complex and realistic settings:

**Population heterogeneity likely lead to simultaneous heterogeneities in MAF and $\beta$, and locus heterogeneity.**  
  
\footnotesize (Codes need to be upgraded if we were to study these more complex settings.)  
\vspace{2cm}

\color{red}BUT, with the **deeper** understanding of all the building blocks, do we really need it?!


## Recap the goal of this lecture: a **deeper** understanding of

\small
Effects of various (population and locus) **heterogeneities**, and the importance of reference allele (and genome build) matching.
\vspace{-3pt}

- my.reference.allele $\neq$ reference.allele
- my.maf $\neq$ ex.maf
- my.beta.true $\neq$ ex.beta.true
- my.nsnp.true $\neq$ ex.nsnp.true
\vspace{12pt}

What's next? There are some limited slides on LD, but **here is a quiz about your current understanding of LD and its impact on PRS.**
\vspace{-3pt}

\footnotesize
- If we were to duplicate (in perfect LD with $r^2=1$) each of the 10 truly associated SNPs, 
- We then proceed as if all SNPs are independent, i.e. LD-unaware PRS
- What would be the AUC of our PRS.oracle, PRS.gw, PRS.01, and PRS.1?
